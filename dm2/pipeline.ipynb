{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Lab 3 Pipeline Assignment\n",
    "\n",
    "**Medium articles** are used to disseminate knowledge and are written on a wide range of technical and non-technical topics. Users subscribe to different reading lists where reading lists represent either domains or certain topics. This naturally gives rise to a network structure where articles may belong to the same reading lists and hence are related to each other. Each article belongs to a certain topic. Automatically assigning articles to topics is very valuable for search applications. **The goal of this task is to classify articles by predicting their topics.**\n",
    "\n",
    "A dataset of medium articles along with subscription lists and topic tags is provided. The task is to classify articles into tags (i.e., topics), leveraging the network structure arising from relations using the subscription lists. Specifically, two nodes are connected if they share at least one list.\n",
    "\n",
    "**For this task you may only use the following libraries**: `numpy`, `pandas`, `matplotlib`, `networkx`, `gensim`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:08.440802Z",
     "start_time": "2024-12-13T13:06:08.407610Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from gensim.models import Word2Vec"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "The data is provided in three files which can be found in the `data` directory:\n",
    "\n",
    "- `articles.csv`: Contains the articles along with the subscription lists and some metadata.\n",
    "- `test_data.csv`: Contains a subset of nodes (articles) along with their labels (topics) used for testing.\n",
    "- `train_data.csv`: Contains the remaining nodes (articles) along with their labels (topics).\n",
    "\n",
    "**Important**: There is no specific training data requried for this assignment, since the node embeddings (task 3) are trained on the entire graph. The nodes in `train_data.csv` must be used for the kNN classifier, i.e., the computed nearest neighbors for a test node may only be nodes from this file.\n",
    "\n",
    "Let's use `pandas` to read these files:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:09.326289Z",
     "start_time": "2024-12-13T13:06:08.524954Z"
    }
   },
   "source": [
    "articles = pd.read_csv(Path(\"data\") / \"articles.csv\")\n",
    "articles[\"node_id\"] = articles.index\n",
    "articles[\"lists\"] = articles[\"lists\"].str.split(\"; \")\n",
    "test_data = pd.read_csv(Path(\"data\") / \"test_data.csv\")\n",
    "train_data = pd.read_csv(Path(\"data\") / \"train_data.csv\")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have assigned node IDs based on where each article is located in the file.\n",
    "\n",
    "We can now inspect the individual data frames:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:09.370817Z",
     "start_time": "2024-12-13T13:06:09.341939Z"
    }
   },
   "source": [
    "articles.head(2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             article  \\\n",
       "0  https://medium.com/@maniakacademy/code-demo-sh...   \n",
       "1  https://medium.com/towards-artificial-intellig...   \n",
       "\n",
       "                                               title  \\\n",
       "0  Code/Demo Share: Palo Alto Firewall Network In...   \n",
       "1              Clustering using Social Graph Network   \n",
       "\n",
       "                                            subtitle                 author  \\\n",
       "0  IP is broken as a unit of Control! IDENTITY as...       Sebastian Maniak   \n",
       "1  A Social Graph Network can be formed when ther...  Naveed Ahmed Janvekar   \n",
       "\n",
       "         date                                              lists  node_id  \n",
       "0  2022-08-17  [https://medium.com/@zemmali1990/list/aws-49f6...        0  \n",
       "1  2022-01-29  [https://medium.com/@TomaszCieplak/list/graph-...        1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>title</th>\n",
       "      <th>subtitle</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>lists</th>\n",
       "      <th>node_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://medium.com/@maniakacademy/code-demo-sh...</td>\n",
       "      <td>Code/Demo Share: Palo Alto Firewall Network In...</td>\n",
       "      <td>IP is broken as a unit of Control! IDENTITY as...</td>\n",
       "      <td>Sebastian Maniak</td>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>[https://medium.com/@zemmali1990/list/aws-49f6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://medium.com/towards-artificial-intellig...</td>\n",
       "      <td>Clustering using Social Graph Network</td>\n",
       "      <td>A Social Graph Network can be formed when ther...</td>\n",
       "      <td>Naveed Ahmed Janvekar</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>[https://medium.com/@TomaszCieplak/list/graph-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:09.553546Z",
     "start_time": "2024-12-13T13:06:09.522628Z"
    }
   },
   "source": [
    "test_data.head(2)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   node_id                    label\n",
       "0     2291  artificial-intelligence\n",
       "1     7292  artificial-intelligence"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2291</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7292</td>\n",
       "      <td>artificial-intelligence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create our graph. We'll create one node for each article and insert an edge between two articles if they share at least one subscription list:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:13.606844Z",
     "start_time": "2024-12-13T13:06:09.660174Z"
    }
   },
   "source": [
    "medium_graph = nx.Graph()\n",
    "medium_graph.add_nodes_from(articles[\"node_id\"].to_list())\n",
    "\n",
    "list_to_nodes = defaultdict(set)\n",
    "for _, row in articles[[\"node_id\", \"lists\"]].iterrows():\n",
    "    for l in row[\"lists\"]:\n",
    "        list_to_nodes[l].add(row[\"node_id\"])\n",
    "\n",
    "for node_ids in list_to_nodes.values():\n",
    "    medium_graph.add_edges_from(combinations(node_ids, 2))"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "1. Familiarization: Analyze the graph. Compute and plot statistics such as the number of nodes, number of edges, number of neighbors of each node, and so on. Are there any isolated nodes (i.e., nodes that do not have a single neighbor)?\n",
    "2. Compute spectral node embeddings.\n",
    "3. Perform random walks on the graph to obtain a set of sequences of nodes. Use those sequences to compute node embeddings. Hint: You may use the Word2vec implementation of the gensim library for this task. By treating each node as a word, this method will give you node embeddings.\n",
    "4. Implement a simple k-nearest neighbor classifier: For each node (medium article) in the test set, compute its nearest neighbors (based on the similarity of node embeddings). The classifier assigns a label (i.e., a topic) based on the topics of the nearest neighbors. Specifically, the predicted topic is simply the most common topic among the nearest neighbors. Compare both sets of node embeddings in terms of performance. Which one works better?\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:13.693395Z",
     "start_time": "2024-12-13T13:06:13.644229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q1\n",
    "num_nodes = medium_graph.number_of_nodes()\n",
    "print(\"Number of nodes:\", num_nodes)\n",
    "num_edges = medium_graph.number_of_edges()\n",
    "print(\"Number of edges:\", num_edges)\n",
    "\n",
    "# Then we also print the degrees of several nodes\n",
    "print_lim = 5\n",
    "isolated = 0\n",
    "for n in medium_graph.nodes:\n",
    "    deg = medium_graph.degree(n)\n",
    "    if print_lim > 0:\n",
    "        print(f\"Node {n} has {deg} neighbors\")\n",
    "        print_lim -= 1\n",
    "    if deg == 0:\n",
    "        isolated += 1\n",
    "print(f\"There are {isolated} isolated nodes\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 27718\n",
      "Number of edges: 2014162\n",
      "Node 0 has 144 neighbors\n",
      "Node 1 has 102 neighbors\n",
      "Node 2 has 18 neighbors\n",
      "Node 3 has 34 neighbors\n",
      "Node 4 has 15 neighbors\n",
      "There are 347 isolated nodes\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:06:13.730856Z",
     "start_time": "2024-12-13T13:06:13.723673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q2\n",
    "def compute_spectral_embeddings(graph: nx.Graph, dim: int) -> np.ndarray:\n",
    "    \"\"\"Perform spectral clustering on the graph and compute low-dimensional node representations.\n",
    "    Does not normalize the Laplacian.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The graph.\n",
    "        dim (int): The dimension of representations. This corresponds to the number of eigenvectors used.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Node representations (sorted by node ID, ascending), shape (num_nodes, dim).\n",
    "    \"\"\"\n",
    "    adjacency_matrix = nx.to_numpy_array(graph, nodelist=sorted(graph.nodes))\n",
    "\n",
    "    # make sure the matrix is symmetric\n",
    "    assert (adjacency_matrix == adjacency_matrix.T).all()\n",
    "\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    L = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        L[i][i] = np.sum(adjacency_matrix[i])\n",
    "    L -= adjacency_matrix\n",
    "    _, evecs = np.linalg.eigh(L)\n",
    "    return evecs[:, :dim]"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:09:46.620809Z",
     "start_time": "2024-12-13T13:09:46.609314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Q3\n",
    "def random_walks(graph: nx.Graph, num_walks: int, walk_length: int) -> np.ndarray:\n",
    "    \"\"\"Perform random walks on an unweighted graph.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The graph.\n",
    "        num_walks (int): The number of random walks for each node.\n",
    "        walk_length (int): The number of nodes in a random walk.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The random walks, shape (n_nodes * num_walks, walk_length)\n",
    "    \"\"\"\n",
    "    result = np.zeros((graph.number_of_nodes() * num_walks, walk_length))\n",
    "\n",
    "    for idx, node in enumerate(graph.nodes):\n",
    "        for walk in range(num_walks):\n",
    "            i = idx * num_walks + walk\n",
    "            for j in range(walk_length):\n",
    "                result[i, j] = node\n",
    "                node = np.random.choice(graph[node])\n",
    "\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We are making a copy of the graph, without the isolated nodes, because the random walks function can't deal with those."
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:08:48.477161Z",
     "start_time": "2024-12-13T13:08:41.134079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_graph = medium_graph.copy()\n",
    "clean_graph.remove_nodes_from([n for n, d in medium_graph.degree() if d == 0])"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-13T13:10:21.793940Z",
     "start_time": "2024-12-13T13:09:50.135844Z"
    }
   },
   "cell_type": "code",
   "source": "print(random_walks(clean_graph, num_walks=5, walk_length=10))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14110. 12088. 15303. ... 24994.  6450. 17537.]\n",
      " [13508. 24762.  3849. ... 12088.   260. 10977.]\n",
      " [17751. 26075. 22490. ... 20404.  6010. 16089.]\n",
      " ...\n",
      " [10861. 23780. 23035. ...  9808.  9808.  8872.]\n",
      " [24823.  8872. 23780. ... 21386. 23035. 21386.]\n",
      " [23780. 21386. 23780. ... 21386. 23780.  9808.]]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
